{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc40c48b-0c95-4757-a067-563cfccd51a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tarefa 1a: executar geração de texto\n",
    "\n",
    "Neste caderno, você aprenderá a usar grandes modelos de linguagem (LLM) para gerar e-mails de resposta destinados a clientes insatisfeitos com a qualidade do atendimento ao cliente prestado pela equipe de suporte. Neste caderno, você gerará um e-mail de agradecimento com base no e-mail anterior do cliente. Você usa o modelo Amazon Titan com a API do Amazon Bedrock e o cliente Boto3.\n",
    "\n",
    "O prompt usado nesta tarefa é chamado de prompt zero-shot. No prompt zero-shot, você usa uma linguagem simples para descrever a tarefa ou a saída desejada ao modelo de linguagem. O modelo usa os recursos e conhecimento pré-treinado para gerar uma resposta ou concluir a tarefa com base somente no prompt fornecido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a413e2-3c34-4073-9000-d8556537bb6a",
   "metadata": {},
   "source": [
    "#### Cenário\n",
    "Você é Bob, um gerente de atendimento ao cliente na UmaEmpresa. Alguns de seus clientes estão insatisfeitos com o atendimento ao cliente e estão reclamando sobre o serviço prestado pela equipe de suporte. Agora, você gostaria de pedir desculpas a esses clientes pelo serviço ruim e recuperar a confiança deles. Você precisa da ajuda de um LLM para gerar vários e-mails de resposta otimistas, personalizados conforme o sentimento descrito no e-mail anterior do cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2797f9",
   "metadata": {},
   "source": [
    "## Tarefa 1a.1: configuração do ambiente\n",
    "\n",
    "Nesta tarefa, você configurará o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776fd083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", \"us-east-1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f634211-3de1-4390-8c3f-367af5554c39",
   "metadata": {},
   "source": [
    "## Tarefa 1a.2: gerar texto\n",
    "\n",
    "Nesta tarefa, você preparará uma entrada para o serviço Amazon Bedrock gerar um e-mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ee2bae-6415-4dba-af98-a19028305c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the prompt\n",
    "prompt_data = \"\"\"\n",
    "Command:Escreva um e-mail de Bob, Gerente de Atendimento ao Cliente da AnyCompany, para o cliente \"John Doe\"\n",
    "que forneceu feedback negativo sobre o serviço prestado pelo nosso engenheiro de suporte ao cliente.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af670eb-ad02-40df-a19c-3ed835fac8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare request body — Amazon Nova Lite format\n",
    "body = json.dumps({\n",
    "    \"inputText\": prompt_data,\n",
    "    \"textGenerationConfig\": {\n",
    "        \"maxTokenCount\": 1000,\n",
    "        \"temperature\": 0.7,\n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1a37c",
   "metadata": {},
   "source": [
    "Em seguida, você usará o modelo Amazon Titan.\n",
    "\n",
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Observação:** o Amazon Titan é compatível com uma janela de contexto de cerca de 4 mil tokens e aceita os seguintes parâmetros:\n",
    "- `inputText`: prompt para o LLM\n",
    "- `textGenerationConfig`: esses são os parâmetros que o modelo levará em consideração ao gerar a saída."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca6751",
   "metadata": {},
   "source": [
    "A API do Amazon Bedrock fornece uma API `invoke_model` que aceita o seguinte:\n",
    "- `modelId`: este é o ARN do modelo para os vários modelos de base disponíveis no Amazon Bedrock\n",
    "- `accept`: o tipo de solicitação de entrada\n",
    "- `contentType`: o tipo de conteúdo da saída\n",
    "- `body`: uma string json que consiste no prompt e nas configurações\n",
    "\n",
    "Consulte a [documentação] (https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html) para ver os IDs dos modelos de geração de texto disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cf6bf-dd73-4710-a0cc-6c11d220c431",
   "metadata": {},
   "source": [
    "## Tarefa 1a.3: invocar o grande modelo de linguagem Amazon Titan\n",
    "\n",
    "Nesta tarefa, você explorará como o modelo gera uma saída com base no prompt criado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379498f2",
   "metadata": {},
   "source": [
    "### Concluir geração de saída\n",
    "\n",
    "O e-mail é gerado pelo modelo Amazon Titan ao entender a solicitação de entrada e usar seu entendimento inerente de diferentes modalidades. A solicitação à API é síncrona e espera que toda a saída seja gerada pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecaceef1-0f7f-4ae5-8007-ff7c25335251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrutura da resposta: dict_keys(['output', 'stopReason', 'usage'])\n",
      "Assunto: Resolução do Problema Encontrado e Melhoria do Nosso Serviço\n",
      "\n",
      "Caro John Doe,\n",
      "\n",
      "Espero que este e-mail o encontre bem. Olá! Meu nome é Bob e sou o Gerente de Atendimento ao Cliente na AnyCompany. Primeiro, gostaria de lhe agradecer por compartilhar seu feedback conosco. \n",
      "\n",
      "Recebemos com seriedade suas preocupações e estamos comprometidos em melhorar nosso serviço. Estamos cientes de que o suporte técnico que você recebeu de nosso engenheiro de suporte ao cliente não atendeu às suas expectativas e, por isso, estamos muito desapontados.\n",
      "\n",
      "Peço suas desculpas sinceras pelo inconveniente que isso possa ter causado. Entendemos o quão frustrante pode ser lidar com problemas técnicos e esperamos que você entenda que não é a política da AnyCompany oferecer um atendimento insatisfatório.\n",
      "\n",
      "Nossa equipe está analisando o caso para identificar o que deu errado e tomar as medidas necessárias para garantir que um incidente como esse não se repita. Além disso, garantimos que o engenheiro de suporte ao cliente que atendeu seu caso será informado sobre suas preocupações e orientado sobre como melhorar sua abordagem e comunicação com os clientes.\n",
      "\n",
      "Estamos empenhados em oferecer um serviço excepcional a todos os nossos clientes e valorizamos muito sua opinião. Para demonstrar nosso compromisso em melhorar, gostaríamos de oferecer um desconto em seu próximo serviço ou uma compensação equivalente, se você considerar apropriado.\n",
      "\n",
      "Estamos aqui para ajudar de qualquer maneira que pudermos e esperamos ter a oportunidade de reverter sua percepção sobre nosso serviço. Por favor, não hesite em entrar em contato conosco, se precisar de mais alguma coisa.\n",
      "\n",
      "Mais uma vez, peço desculpas sinceras pelo inconveniente e agradeço por compartilhar suas preocupações conosco.\n",
      "\n",
      "Atenciosamente,\n",
      "\n",
      "Bob\n",
      "Gerente de Atendimento ao Cliente\n",
      "AnyCompany\n",
      "[Seu número de telefone]\n",
      "[Seu endereço de e-mail]\n"
     ]
    }
   ],
   "source": [
    "#invoke model\n",
    "# Use Amazon Nova Lite como substituto\n",
    "modelId = 'amazon.nova-lite-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "try:\n",
    "    response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    # Nova usa formato diferente - verifique a estrutura da resposta\n",
    "    print(\"Estrutura da resposta:\", response_body.keys())\n",
    "    \n",
    "    # Tente extrair o texto (formato pode variar)\n",
    "    if 'output' in response_body:\n",
    "        outputText = response_body['output']['message']['content'][0]['text']\n",
    "    elif 'outputText' in response_body:\n",
    "        outputText = response_body['outputText']\n",
    "    else:\n",
    "        print(\"Resposta completa:\", response_body)\n",
    "        \n",
    "    print(outputText)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3748383a-c140-407f-a7f6-8f140ad57680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caro John Doe,\n",
      "\n",
      "Espero que este e-mail o encontre bem. Olá! Meu nome é Bob e sou o Gerente de Atendimento ao Cliente na AnyCompany. Primeiro, gostaria de lhe agradecer por compartilhar seu feedback conosco. \n",
      "\n",
      "Recebemos com seriedade suas preocupações e estamos comprometidos em melhorar nosso serviço. Estamos cientes de que o suporte técnico que você recebeu de nosso engenheiro de suporte ao cliente não atendeu às suas expectativas e, por isso, estamos muito desapontados.\n",
      "\n",
      "Peço suas desculpas sinceras pelo inconveniente que isso possa ter causado. Entendemos o quão frustrante pode ser lidar com problemas técnicos e esperamos que você entenda que não é a política da AnyCompany oferecer um atendimento insatisfatório.\n",
      "\n",
      "Nossa equipe está analisando o caso para identificar o que deu errado e tomar as medidas necessárias para garantir que um incidente como esse não se repita. Além disso, garantimos que o engenheiro de suporte ao cliente que atendeu seu caso será informado sobre suas preocupações e orientado sobre como melhorar sua abordagem e comunicação com os clientes.\n",
      "\n",
      "Estamos empenhados em oferecer um serviço excepcional a todos os nossos clientes e valorizamos muito sua opinião. Para demonstrar nosso compromisso em melhorar, gostaríamos de oferecer um desconto em seu próximo serviço ou uma compensação equivalente, se você considerar apropriado.\n",
      "\n",
      "Estamos aqui para ajudar de qualquer maneira que pudermos e esperamos ter a oportunidade de reverter sua percepção sobre nosso serviço. Por favor, não hesite em entrar em contato conosco, se precisar de mais alguma coisa.\n",
      "\n",
      "Mais uma vez, peço desculpas sinceras pelo inconveniente e agradeço por compartilhar suas preocupações conosco.\n",
      "\n",
      "Atenciosamente,\n",
      "\n",
      "Bob\n",
      "Gerente de Atendimento ao Cliente\n",
      "AnyCompany\n",
      "[Seu número de telefone]\n",
      "[Seu endereço de e-mail]\n"
     ]
    }
   ],
   "source": [
    "# The relevant portion of the response begins after the first newline character\n",
    "# Below we print the response beginning after the first occurence of '\\n'.\n",
    "\n",
    "email = outputText[outputText.index('\\n')+1:]\n",
    "print(email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69e1a0",
   "metadata": {},
   "source": [
    "### Transmitir geração de saída\n",
    "\n",
    "O Bedrock também pode transmitir a saída em forma de blocos, à medida que ela é gerada pelo modelo. Esse e-mail é gerado invocando o modelo com a opção de streaming. `invoke_model_with_response_stream` retorna um `ResponseStream` do qual você pode ler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad073290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# invoke model with response stream\n",
    "output = []\n",
    "try:\n",
    "    response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    stream = response.get('body')\n",
    "        \n",
    "    i = 1\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk['bytes'].decode())\n",
    "            \n",
    "            # Processa contentBlockDelta (texto real)\n",
    "            if 'contentBlockDelta' in chunk_obj:\n",
    "                text = chunk_obj['contentBlockDelta']['delta']['text']\n",
    "                output.append(text)\n",
    "                i += 1\n",
    "                        \n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a788be5",
   "metadata": {},
   "source": [
    "A abordagem de transmissão com resposta ajuda a obter rapidamente a saída do modelo e permite que o serviço a conclua enquanto você lê. Isso ajuda nos casos de uso em que você solicita que o modelo gere trechos de texto mais longos. Posteriormente, você pode combinar todos os blocos gerados para formar a saída completa e usá-la no seu caso de uso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02d48c73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\u001b[31m**COMPLETE OUTPUT**\u001b[0m\n",
      "\n",
      "Assunto: Resolução do Feedback Recebido\n",
      "\n",
      "Olá John,\n",
      "\n",
      "Espero que você esteja bem.\n",
      "\n",
      "Primeiramente, gostaria de agradecer por compartilhar seu feedback sobre a recente experiência que você teve com nosso engenheiro de suporte ao cliente. Lamento profundamente que nossa equipe não tenha atendido às suas expectativas e por qualquer inconveniente que isso possa ter causado.\n",
      "\n",
      "Na AnyCompany, valorizamos muito a satisfação do cliente e nos esforçamos para fornecer o melhor serviço possível. No entanto, sabemos que ainda há espaço para melhorias e estamos empenhados em garantir que situações como essa não se repitam.\n",
      "\n",
      "Gostaria de pedir um pouco mais de tempo para investigar minuciosamente o que ocorreu e entender melhor suas preocupações. Além disso, posso providenciar uma reunião com um de nossos engenheiros seniores para discutir suas necessidades e garantir que todas as suas questões sejam devidamente abordadas.\n",
      "\n",
      "Estamos comprometidos em encontrar uma solução satisfatória para você e, se possível, gostaria de agendar uma chamada para discutir suas expectativas e como podemos superá-las. Estou à disposição para marcar um horário que seja conveniente para você.\n",
      "\n",
      "Mais uma vez, peço desculpas pelo inconveniente e agradeço por trazer esse problema à nossa atenção. Estamos aqui para ajudar e garantir que você tenha uma experiência positiva com a AnyCompany.\n",
      "\n",
      "Aguardo seu retorno para que possamos dar prosseguimento ao atendimento da sua solicitação.\n",
      "\n",
      "Atenciosamente,\n",
      "\n",
      "Bob  \n",
      "Gerente de Atendimento ao Cliente  \n",
      "AnyCompany  \n",
      "[Seu telefone]  \n",
      "[Seu e-mail]\n"
     ]
    }
   ],
   "source": [
    "#combine output chunks\n",
    "print('\\n\\t\\t\\x1b[31m**COMPLETE OUTPUT**\\x1b[0m\\n')\n",
    "complete_output = ''.join(output)\n",
    "print(complete_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b08b3b",
   "metadata": {},
   "source": [
    "\n",
    "Você testou o uso do SDK boto3, que oferece uma exposição básica à API do Amazon Bedrock. Ao usar essa API, você viu o caso de uso de geração de e-mails de resposta a clientes insatisfeitos.\n",
    "\n",
    "### Experimente você mesmo\n",
    "- Altere os prompts para seu caso de uso específico e avalie o resultado de diferentes modelos.\n",
    "- Teste o comprimento do token para entender a latência e a responsividade do serviço.\n",
    "- Aplique diferentes princípios de engenharia de prompts para gerar resultados melhores.\n",
    "\n",
    "### Limpeza\n",
    "\n",
    "Você concluiu este caderno. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de caderno e continue com **Task1b.ipynb**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
